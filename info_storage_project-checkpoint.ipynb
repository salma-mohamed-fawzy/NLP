{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f992437",
   "metadata": {},
   "source": [
    "# Sentence similarity project\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e724eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract similarity betweem different sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "694cdb80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in c:\\users\\salma\\anaconda3\\lib\\site-packages (4.2.0)\n",
      "Requirement already satisfied: Cython==0.29.28 in c:\\users\\salma\\anaconda3\\lib\\site-packages (from gensim) (0.29.28)\n",
      "Requirement already satisfied: scipy>=0.18.1 in c:\\users\\salma\\anaconda3\\lib\\site-packages (from gensim) (1.7.1)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\salma\\anaconda3\\lib\\site-packages (from gensim) (1.20.3)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\salma\\anaconda3\\lib\\site-packages (from gensim) (5.2.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6bd92713",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in c:\\users\\salma\\anaconda3\\lib\\site-packages (3.3.0)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in c:\\users\\salma\\anaconda3\\lib\\site-packages (from spacy) (0.7.7)\n",
      "Requirement already satisfied: setuptools in c:\\users\\salma\\anaconda3\\lib\\site-packages (from spacy) (58.0.4)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\salma\\anaconda3\\lib\\site-packages (from spacy) (3.3.0)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in c:\\users\\salma\\anaconda3\\lib\\site-packages (from spacy) (0.9.1)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in c:\\users\\salma\\anaconda3\\lib\\site-packages (from spacy) (1.8.2)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in c:\\users\\salma\\anaconda3\\lib\\site-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\salma\\anaconda3\\lib\\site-packages (from spacy) (2.4.3)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\salma\\anaconda3\\lib\\site-packages (from spacy) (2.0.6)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\salma\\anaconda3\\lib\\site-packages (from spacy) (1.0.2)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\salma\\anaconda3\\lib\\site-packages (from spacy) (3.0.6)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\salma\\anaconda3\\lib\\site-packages (from spacy) (2.0.7)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.14 in c:\\users\\salma\\anaconda3\\lib\\site-packages (from spacy) (8.0.16)\n",
      "Requirement already satisfied: pathy>=0.3.5 in c:\\users\\salma\\anaconda3\\lib\\site-packages (from spacy) (0.6.1)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\salma\\anaconda3\\lib\\site-packages (from spacy) (1.0.7)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\salma\\anaconda3\\lib\\site-packages (from spacy) (4.62.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\salma\\anaconda3\\lib\\site-packages (from spacy) (2.11.3)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in c:\\users\\salma\\anaconda3\\lib\\site-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\salma\\anaconda3\\lib\\site-packages (from spacy) (1.20.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\salma\\anaconda3\\lib\\site-packages (from spacy) (21.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\salma\\anaconda3\\lib\\site-packages (from spacy) (2.26.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\salma\\anaconda3\\lib\\site-packages (from packaging>=20.0->spacy) (3.0.4)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in c:\\users\\salma\\anaconda3\\lib\\site-packages (from pathy>=0.3.5->spacy) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\salma\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy) (3.10.0.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\salma\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\salma\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\salma\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\salma\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.7)\n",
      "Requirement already satisfied: colorama in c:\\users\\salma\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\salma\\anaconda3\\lib\\site-packages (from typer<0.5.0,>=0.3.0->spacy) (8.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\salma\\anaconda3\\lib\\site-packages (from jinja2->spacy) (1.1.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e672b87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nlp in c:\\users\\salma\\anaconda3\\lib\\site-packages (0.4.0)\n",
      "Requirement already satisfied: pyarrow>=0.16.0 in c:\\users\\salma\\anaconda3\\lib\\site-packages (from nlp) (8.0.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\salma\\anaconda3\\lib\\site-packages (from nlp) (3.3.1)\n",
      "Requirement already satisfied: dill in c:\\users\\salma\\anaconda3\\lib\\site-packages (from nlp) (0.3.4)\n",
      "Requirement already satisfied: xxhash in c:\\users\\salma\\anaconda3\\lib\\site-packages (from nlp) (3.0.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\salma\\anaconda3\\lib\\site-packages (from nlp) (4.62.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\salma\\anaconda3\\lib\\site-packages (from nlp) (2.26.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\salma\\anaconda3\\lib\\site-packages (from nlp) (1.3.4)\n",
      "Requirement already satisfied: numpy in c:\\users\\salma\\anaconda3\\lib\\site-packages (from nlp) (1.20.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\salma\\anaconda3\\lib\\site-packages (from requests>=2.19.0->nlp) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\salma\\anaconda3\\lib\\site-packages (from requests>=2.19.0->nlp) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\salma\\anaconda3\\lib\\site-packages (from requests>=2.19.0->nlp) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\salma\\anaconda3\\lib\\site-packages (from requests>=2.19.0->nlp) (3.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\salma\\anaconda3\\lib\\site-packages (from tqdm>=4.27->nlp) (0.4.4)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\salma\\anaconda3\\lib\\site-packages (from pandas->nlp) (2021.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\salma\\anaconda3\\lib\\site-packages (from pandas->nlp) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\salma\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7.3->pandas->nlp) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7da20bb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.3.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.3.0/en_core_web_sm-3.3.0-py3-none-any.whl (12.8 MB)\n",
      "Requirement already satisfied: spacy<3.4.0,>=3.3.0.dev0 in c:\\users\\salma\\anaconda3\\lib\\site-packages (from en-core-web-sm==3.3.0) (3.3.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in c:\\users\\salma\\anaconda3\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.8.2)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\salma\\anaconda3\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.0.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\salma\\anaconda3\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.3.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\salma\\anaconda3\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (4.62.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\salma\\anaconda3\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (21.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\salma\\anaconda3\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.0.7)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\salma\\anaconda3\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.26.0)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\salma\\anaconda3\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.4.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\salma\\anaconda3\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.11.3)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.14 in c:\\users\\salma\\anaconda3\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (8.0.16)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\salma\\anaconda3\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.20.3)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\salma\\anaconda3\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.0.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\salma\\anaconda3\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (58.0.4)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in c:\\users\\salma\\anaconda3\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (0.9.1)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in c:\\users\\salma\\anaconda3\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.0.9)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\salma\\anaconda3\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.0.6)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in c:\\users\\salma\\anaconda3\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (0.4.1)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in c:\\users\\salma\\anaconda3\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (0.7.7)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\salma\\anaconda3\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.0.7)\n",
      "Requirement already satisfied: pathy>=0.3.5 in c:\\users\\salma\\anaconda3\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (0.6.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\salma\\anaconda3\\lib\\site-packages (from packaging>=20.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.0.4)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in c:\\users\\salma\\anaconda3\\lib\\site-packages (from pathy>=0.3.5->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\salma\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.10.0.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\salma\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\salma\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\salma\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.2)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\salma\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.0.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\salma\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (0.4.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\salma\\anaconda3\\lib\\site-packages (from typer<0.5.0,>=0.3.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (8.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\salma\\anaconda3\\lib\\site-packages (from jinja2->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.1.1)\n",
      "[!] As of spaCy v3.0, shortcuts like 'en' are deprecated. Please use the full\n",
      "pipeline package name 'en_core_web_sm' instead.\n",
      "[+] Download and installation successful\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d18f64bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-lg==3.3.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.3.0/en_core_web_lg-3.3.0-py3-none-any.whl (400.7 MB)\n",
      "Requirement already satisfied: spacy<3.4.0,>=3.3.0.dev0 in c:\\users\\salma\\anaconda3\\lib\\site-packages (from en-core-web-lg==3.3.0) (3.3.0)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.14 in c:\\users\\salma\\anaconda3\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-lg==3.3.0) (8.0.16)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\salma\\anaconda3\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-lg==3.3.0) (4.62.3)\n",
      "Requirement already satisfied: pathy>=0.3.5 in c:\\users\\salma\\anaconda3\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-lg==3.3.0) (0.6.1)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in c:\\users\\salma\\anaconda3\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-lg==3.3.0) (0.7.7)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in c:\\users\\salma\\anaconda3\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-lg==3.3.0) (0.4.1)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in c:\\users\\salma\\anaconda3\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-lg==3.3.0) (1.8.2)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\salma\\anaconda3\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-lg==3.3.0) (3.0.6)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\salma\\anaconda3\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-lg==3.3.0) (3.3.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\salma\\anaconda3\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-lg==3.3.0) (2.26.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\salma\\anaconda3\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-lg==3.3.0) (1.0.7)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\salma\\anaconda3\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-lg==3.3.0) (1.0.2)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\salma\\anaconda3\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-lg==3.3.0) (1.20.3)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in c:\\users\\salma\\anaconda3\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-lg==3.3.0) (0.9.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\salma\\anaconda3\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-lg==3.3.0) (21.0)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in c:\\users\\salma\\anaconda3\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-lg==3.3.0) (3.0.9)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\salma\\anaconda3\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-lg==3.3.0) (2.4.3)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\salma\\anaconda3\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-lg==3.3.0) (2.0.7)\n",
      "Requirement already satisfied: setuptools in c:\\users\\salma\\anaconda3\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-lg==3.3.0) (58.0.4)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\salma\\anaconda3\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-lg==3.3.0) (2.11.3)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\salma\\anaconda3\\lib\\site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-lg==3.3.0) (2.0.6)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\salma\\anaconda3\\lib\\site-packages (from packaging>=20.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-lg==3.3.0) (3.0.4)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in c:\\users\\salma\\anaconda3\\lib\\site-packages (from pathy>=0.3.5->spacy<3.4.0,>=3.3.0.dev0->en-core-web-lg==3.3.0) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\salma\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy<3.4.0,>=3.3.0.dev0->en-core-web-lg==3.3.0) (3.10.0.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\salma\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-lg==3.3.0) (3.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\salma\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-lg==3.3.0) (1.26.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\salma\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-lg==3.3.0) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\salma\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-lg==3.3.0) (2021.10.8)\n",
      "Requirement already satisfied: colorama in c:\\users\\salma\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-lg==3.3.0) (0.4.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\salma\\anaconda3\\lib\\site-packages (from typer<0.5.0,>=0.3.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-lg==3.3.0) (8.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\salma\\anaconda3\\lib\\site-packages (from jinja2->spacy<3.4.0,>=3.3.0.dev0->en-core-web-lg==3.3.0) (1.1.1)\n",
      "[+] Download and installation successful\n",
      "You can now load the package via spacy.load('en_core_web_lg')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "696a3f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "import math\n",
    "import os\n",
    "import gensim\n",
    "import spacy \n",
    "nlp=spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffcdf3bb",
   "metadata": {},
   "source": [
    "# reading  data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58e136b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unique_ID</th>\n",
       "      <th>text1</th>\n",
       "      <th>text2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>savvy searchers fail to spot ads internet sear...</td>\n",
       "      <td>newcastle 2-1 bolton kieron dyer smashed home ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>millions to miss out on the net by 2025  40% o...</td>\n",
       "      <td>nasdaq planning $100m share sale the owner of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>young debut cut short by ginepri fifteen-year-...</td>\n",
       "      <td>ruddock backs yapp s credentials wales coach m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>diageo to buy us wine firm diageo  the world s...</td>\n",
       "      <td>mci shares climb on takeover bid shares in us ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>be careful how you code a new european directi...</td>\n",
       "      <td>media gadgets get moving pocket-sized devices ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unique_ID                                              text1  \\\n",
       "0          0  savvy searchers fail to spot ads internet sear...   \n",
       "1          1  millions to miss out on the net by 2025  40% o...   \n",
       "2          2  young debut cut short by ginepri fifteen-year-...   \n",
       "3          3  diageo to buy us wine firm diageo  the world s...   \n",
       "4          4  be careful how you code a new european directi...   \n",
       "\n",
       "                                               text2  \n",
       "0  newcastle 2-1 bolton kieron dyer smashed home ...  \n",
       "1  nasdaq planning $100m share sale the owner of ...  \n",
       "2  ruddock backs yapp s credentials wales coach m...  \n",
       "3  mci shares climb on takeover bid shares in us ...  \n",
       "4  media gadgets get moving pocket-sized devices ...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('text similarity\\Text_Similarity_Dataset.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607a17b4",
   "metadata": {},
   "source": [
    "# preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10a970fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'savvy searchers fail to spot ads internet search engine users are an odd mix of naive and sophisticated  suggests a report into search habits.  the report by the us pew research center reveals that 87% of searchers usually find what they were looking for when using a search engine. it also shows that few can spot the difference between paid-for results and organic ones. the report reveals that 84% of net users say they regularly use google  ask jeeves  msn and yahoo when online.  almost 50% of those questioned said they would trust search engines much less  if they knew information about who paid for results was being hidden. according to figures gathered by the pew researchers the average users spends about 43 minutes per month carrying out 34 separate searches and looks at 1.9 webpages for each hunt. a significant chunk of net users  36%  carry out a search at least weekly and 29% of those asked only look every few weeks. for 44% of those questioned  the information they are looking for is critical to what they are doing and is information they simply have to find.  search engine users also tend to be very loyal and once they have found a site they feel they can trust tend to stick with it. according to pew research 44% of searchers use just a single search engine  48% use two or three and a small number  7%  consult more than three sites. tony macklin  spokesman for ask jeeves  said the results reflected its own research which showed that people use different search engines because the way the sites gather information means they can provide different results for the same query. despite this liking for search sites half of those questioned said they could get the same information via other routes. a small number  17%  said they wouldn t really miss search engines if they did not exist. the remaining 33% said they could not live without search sites. more than two-thirds of those questioned  68%  said they thought that the results they were presented with were a fair and unbiased selection of the information on a topic that can be found on the net. alongside the growing sophistication of net users is a lack of awareness about paid-for results that many search engines provide alongside lists of websites found by indexing the web. of those asked  62% were unaware that someone has paid for some of the results they see when they carry out a search. only 18% of all searchers say they can tell which results are paid for and which are not. said the pew report:  this finding is ironic  since nearly half of all users say they would stop using search engines if they thought engines were not being clear about how they presented paid results.  commenting mr macklin said sponsored results must be clearly marked and though they might help with some queries user testing showed that people need to be able to spot the difference.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['text1'][0] # read each column seperately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0eea4fe5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'newcastle 2-1 bolton kieron dyer smashed home the winner to end bolton s 10-game unbeaten run.  lee bowyer put newcastle ahead when he fed stephen carr on the right flank  then sprinted into the area to power home a header from the resultant cross. wanderers hit back through stelios giannakopoulos  who ended a fluid passing move with a well-struck volley. but dyer had the last word in a game of few chances  pouncing on a loose ball after alan shearer s shot was blocked and firing into the top corner. neither side lacked urgency in the early stages of the game  with plenty of tackles flying in  but opportunities in front of goal were harder to come by. bolton keeper jussi jaaskelainen had to make two saves in quick succession midway through the first-half - keeping out shearer s low shot and dyer s close-range header - but that was the only goalmouth action of note. and it was almost out of nothing that the magpies took the lead on 35 minutes. bowyer found space with a neat turn on the half-way line and striding forward picked out carr to his right. he then continued his run and with perfect timing made his way into the box where he met carr s cross with a downward header into the far corner. bolton had produced little going forward at this point but they responded well.  they were level within six minutes thanks to a smart finish from giannakopoulos. jay-jay okocha twisted and turned on the edge of the area and after a neat exchange of passes involving kevin davies and gary speed  the greek striker found the bottom corner with a first-time strike. the magpies were opened up again before half-time as davies set giannakopoulos in space and given had to block at his near post. but the home side survived  and they should have re-taken the lead with the first meaningful attack of the second half. fernando hierro cynically chopped down dyer on the edge of the area with the midfielder clean through. but the veteran defender escaped with a booking as there were other defenders nearby  and from the resultant free-kick laurent robert curled the ball just wide. bolton were creating little going forward and they seemed content to frustrate the magpies. their strategy seemed to be working until the 69th minute. alan shearer s snap-shot was charged down and dyer reacted first to smash the ball past the despairing jaaskelainen from six yards.  - bolton boss sam allardyce  i am bitterly disappointed with the result  but i am probably more disappointed with the second-half performance.  in the first half we had put them under a lot of pressure  and our goal matched theirs in quality.  i thought it would lift us and that they might be tired after playing a lot of games  but unfortunately we were not up for the battle in the second half.  we allowed them to heap too much pressure on us  and in the end we cracked.    - newcastle boss graeme souness  we deserved the win. we had a really good second half.  bolton are a difficult side to play. you have to match them physically first but we did that  and then we played some football.  we had a slow first 45 minutes when we looked a bit tired but we got going after that. the scoreline flattered them and we could have had one or two more goals.  newcastle: given  carr  boumsong  bramble  babayaro  dyer  faye  bowyer  robert (jenas 77)  ameobi  shearer. subs not used: butt  harper  milner  hughes. goals: bowyer 35  dyer 69. bolton: jaaskelainen  hunt (fadiga 14)  n gotty  ben haim  candela  giannakopoulos  okocha (vaz te 77)  hierro (campo 64)  speed  gardner  davies. subs not used: jaidi  poole. booked: ben haim  hierro. goals: giannakopoulos 41. att: 50 430 ref: s dunn (gloucestershire).'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['text2'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec301b99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "savvy searchers fail to spot ads internet search engine users are an odd mix of naive and sophisticated  suggests a report into search habits.  the report by the us pew research center reveals that 87% of searchers usually find what they were looking for when using a search engine. it also shows that few can spot the difference between paid-for results and organic ones. the report reveals that 84% of net users say they regularly use google  ask jeeves  msn and yahoo when online.  almost 50% of those questioned said they would trust search engines much less  if they knew information about who paid for results was being hidden. according to figures gathered by the pew researchers the average users spends about 43 minutes per month carrying out 34 separate searches and looks at 1.9 webpages for each hunt. a significant chunk of net users  36%  carry out a search at least weekly and 29% of those asked only look every few weeks. for 44% of those questioned  the information they are looking for is critical to what they are doing and is information they simply have to find.  search engine users also tend to be very loyal and once they have found a site they feel they can trust tend to stick with it. according to pew research 44% of searchers use just a single search engine  48% use two or three and a small number  7%  consult more than three sites. tony macklin  spokesman for ask jeeves  said the results reflected its own research which showed that people use different search engines because the way the sites gather information means they can provide different results for the same query. despite this liking for search sites half of those questioned said they could get the same information via other routes. a small number  17%  said they wouldn t really miss search engines if they did not exist. the remaining 33% said they could not live without search sites. more than two-thirds of those questioned  68%  said they thought that the results they were presented with were a fair and unbiased selection of the information on a topic that can be found on the net. alongside the growing sophistication of net users is a lack of awareness about paid-for results that many search engines provide alongside lists of websites found by indexing the web. of those asked  62% were unaware that someone has paid for some of the results they see when they carry out a search. only 18% of all searchers say they can tell which results are paid for and which are not. said the pew report:  this finding is ironic  since nearly half of all users say they would stop using search engines if they thought engines were not being clear about how they presented paid results.  commenting mr macklin said sponsored results must be clearly marked and though they might help with some queries user testing showed that people need to be able to spot the difference.\n"
     ]
    }
   ],
   "source": [
    "#lowercase\n",
    "print(data['text1'][0].lower())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "86851bb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newcastle 2-1 bolton kieron dyer smashed home the winner to end bolton s 10-game unbeaten run.  lee bowyer put newcastle ahead when he fed stephen carr on the right flank  then sprinted into the area to power home a header from the resultant cross. wanderers hit back through stelios giannakopoulos  who ended a fluid passing move with a well-struck volley. but dyer had the last word in a game of few chances  pouncing on a loose ball after alan shearer s shot was blocked and firing into the top corner. neither side lacked urgency in the early stages of the game  with plenty of tackles flying in  but opportunities in front of goal were harder to come by. bolton keeper jussi jaaskelainen had to make two saves in quick succession midway through the first-half - keeping out shearer s low shot and dyer s close-range header - but that was the only goalmouth action of note. and it was almost out of nothing that the magpies took the lead on 35 minutes. bowyer found space with a neat turn on the half-way line and striding forward picked out carr to his right. he then continued his run and with perfect timing made his way into the box where he met carr s cross with a downward header into the far corner. bolton had produced little going forward at this point but they responded well.  they were level within six minutes thanks to a smart finish from giannakopoulos. jay-jay okocha twisted and turned on the edge of the area and after a neat exchange of passes involving kevin davies and gary speed  the greek striker found the bottom corner with a first-time strike. the magpies were opened up again before half-time as davies set giannakopoulos in space and given had to block at his near post. but the home side survived  and they should have re-taken the lead with the first meaningful attack of the second half. fernando hierro cynically chopped down dyer on the edge of the area with the midfielder clean through. but the veteran defender escaped with a booking as there were other defenders nearby  and from the resultant free-kick laurent robert curled the ball just wide. bolton were creating little going forward and they seemed content to frustrate the magpies. their strategy seemed to be working until the 69th minute. alan shearer s snap-shot was charged down and dyer reacted first to smash the ball past the despairing jaaskelainen from six yards.  - bolton boss sam allardyce  i am bitterly disappointed with the result  but i am probably more disappointed with the second-half performance.  in the first half we had put them under a lot of pressure  and our goal matched theirs in quality.  i thought it would lift us and that they might be tired after playing a lot of games  but unfortunately we were not up for the battle in the second half.  we allowed them to heap too much pressure on us  and in the end we cracked.    - newcastle boss graeme souness  we deserved the win. we had a really good second half.  bolton are a difficult side to play. you have to match them physically first but we did that  and then we played some football.  we had a slow first 45 minutes when we looked a bit tired but we got going after that. the scoreline flattered them and we could have had one or two more goals.  newcastle: given  carr  boumsong  bramble  babayaro  dyer  faye  bowyer  robert (jenas 77)  ameobi  shearer. subs not used: butt  harper  milner  hughes. goals: bowyer 35  dyer 69. bolton: jaaskelainen  hunt (fadiga 14)  n gotty  ben haim  candela  giannakopoulos  okocha (vaz te 77)  hierro (campo 64)  speed  gardner  davies. subs not used: jaidi  poole. booked: ben haim  hierro. goals: giannakopoulos 41. att: 50 430 ref: s dunn (gloucestershire).\n"
     ]
    }
   ],
   "source": [
    "print(data['text2'][0].lower())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "23005cf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "15774ec1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'savvy searchers fail to spot ads internet search engine users are an odd mix of naive and sophisticated  suggests a report into search habits   the report by the us pew research center reveals that 87  of searchers usually find what they were looking for when using a search engine  it also shows that few can spot the difference between paid for results and organic ones  the report reveals that 84  of net users say they regularly use google  ask jeeves  msn and yahoo when online   almost 50  of those questioned said they would trust search engines much less  if they knew information about who paid for results was being hidden  according to figures gathered by the pew researchers the average users spends about 43 minutes per month carrying out 34 separate searches and looks at 1 9 webpages for each hunt  a significant chunk of net users  36   carry out a search at least weekly and 29  of those asked only look every few weeks  for 44  of those questioned  the information they are looking for is critical to what they are doing and is information they simply have to find   search engine users also tend to be very loyal and once they have found a site they feel they can trust tend to stick with it  according to pew research 44  of searchers use just a single search engine  48  use two or three and a small number  7   consult more than three sites  tony macklin  spokesman for ask jeeves  said the results reflected its own research which showed that people use different search engines because the way the sites gather information means they can provide different results for the same query  despite this liking for search sites half of those questioned said they could get the same information via other routes  a small number  17   said they wouldn t really miss search engines if they did not exist  the remaining 33  said they could not live without search sites  more than two thirds of those questioned  68   said they thought that the results they were presented with were a fair and unbiased selection of the information on a topic that can be found on the net  alongside the growing sophistication of net users is a lack of awareness about paid for results that many search engines provide alongside lists of websites found by indexing the web  of those asked  62  were unaware that someone has paid for some of the results they see when they carry out a search  only 18  of all searchers say they can tell which results are paid for and which are not  said the pew report   this finding is ironic  since nearly half of all users say they would stop using search engines if they thought engines were not being clear about how they presented paid results   commenting mr macklin said sponsored results must be clearly marked and though they might help with some queries user testing showed that people need to be able to spot the difference '"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#remove punctuation\n",
    "data['text1'] = data['text1'].apply(lambda x: re.sub('[%s]' % re.escape(string.punctuation), ' ' , x))\n",
    "data['text1'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "28df2642",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'newcastle 2 1 bolton kieron dyer smashed home the winner to end bolton s 10 game unbeaten run   lee bowyer put newcastle ahead when he fed stephen carr on the right flank  then sprinted into the area to power home a header from the resultant cross  wanderers hit back through stelios giannakopoulos  who ended a fluid passing move with a well struck volley  but dyer had the last word in a game of few chances  pouncing on a loose ball after alan shearer s shot was blocked and firing into the top corner  neither side lacked urgency in the early stages of the game  with plenty of tackles flying in  but opportunities in front of goal were harder to come by  bolton keeper jussi jaaskelainen had to make two saves in quick succession midway through the first half   keeping out shearer s low shot and dyer s close range header   but that was the only goalmouth action of note  and it was almost out of nothing that the magpies took the lead on 35 minutes  bowyer found space with a neat turn on the half way line and striding forward picked out carr to his right  he then continued his run and with perfect timing made his way into the box where he met carr s cross with a downward header into the far corner  bolton had produced little going forward at this point but they responded well   they were level within six minutes thanks to a smart finish from giannakopoulos  jay jay okocha twisted and turned on the edge of the area and after a neat exchange of passes involving kevin davies and gary speed  the greek striker found the bottom corner with a first time strike  the magpies were opened up again before half time as davies set giannakopoulos in space and given had to block at his near post  but the home side survived  and they should have re taken the lead with the first meaningful attack of the second half  fernando hierro cynically chopped down dyer on the edge of the area with the midfielder clean through  but the veteran defender escaped with a booking as there were other defenders nearby  and from the resultant free kick laurent robert curled the ball just wide  bolton were creating little going forward and they seemed content to frustrate the magpies  their strategy seemed to be working until the 69th minute  alan shearer s snap shot was charged down and dyer reacted first to smash the ball past the despairing jaaskelainen from six yards     bolton boss sam allardyce  i am bitterly disappointed with the result  but i am probably more disappointed with the second half performance   in the first half we had put them under a lot of pressure  and our goal matched theirs in quality   i thought it would lift us and that they might be tired after playing a lot of games  but unfortunately we were not up for the battle in the second half   we allowed them to heap too much pressure on us  and in the end we cracked       newcastle boss graeme souness  we deserved the win  we had a really good second half   bolton are a difficult side to play  you have to match them physically first but we did that  and then we played some football   we had a slow first 45 minutes when we looked a bit tired but we got going after that  the scoreline flattered them and we could have had one or two more goals   newcastle  given  carr  boumsong  bramble  babayaro  dyer  faye  bowyer  robert  jenas 77   ameobi  shearer  subs not used  butt  harper  milner  hughes  goals  bowyer 35  dyer 69  bolton  jaaskelainen  hunt  fadiga 14   n gotty  ben haim  candela  giannakopoulos  okocha  vaz te 77   hierro  campo 64   speed  gardner  davies  subs not used  jaidi  poole  booked  ben haim  hierro  goals  giannakopoulos 41  att  50 430 ref  s dunn  gloucestershire  '"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['text2'] = data['text2'].apply(lambda x: re.sub('[%s]' % re.escape(string.punctuation), ' ' , x))\n",
    "data['text2'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b6d074fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SaLmA\\AppData\\Local\\Temp/ipykernel_11964/3213931687.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['text1'][0] = ''.join([i for i in data['text1'][0] if not i.isdigit()])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'savvy searchers fail to spot as internet search engine users are an o mix of naive an sophisticate  suggests a report into search habits   the report by the us pew research center reveals that   of searchers usually fin what they were looking for when using a search engine  it also shows that few can spot the ifference between pai for results an organic ones  the report reveals that   of net users say they regularly use google  ask jeeves  msn an yahoo when online   almost   of those questione sai they woul trust search engines much less  if they knew information about who pai for results was being hien  accoring to figures gathere by the pew researchers the average users spens about  minutes per month carrying out  separate searches an looks at   webpages for each hunt  a significant chunk of net users     carry out a search at least weekly an   of those aske only look every few weeks  for   of those questione  the information they are looking for is critical to what they are oing an is information they simply have to fin   search engine users also ten to be very loyal an once they have foun a site they feel they can trust ten to stick with it  accoring to pew research   of searchers use just a single search engine    use two or three an a small number     consult more than three sites  tony macklin  spokesman for ask jeeves  sai the results reflecte its own research which showe that people use ifferent search engines because the way the sites gather information means they can provie ifferent results for the same query  espite this liking for search sites half of those questione sai they coul get the same information via other routes  a small number     sai they wouln t really miss search engines if they i not exist  the remaining   sai they coul not live without search sites  more than two thirs of those questione     sai they thought that the results they were presente with were a fair an unbiase selection of the information on a topic that can be foun on the net  alongsie the growing sophistication of net users is a lack of awareness about pai for results that many search engines provie alongsie lists of websites foun by inexing the web  of those aske    were unaware that someone has pai for some of the results they see when they carry out a search  only   of all searchers say they can tell which results are pai for an which are not  sai the pew report   this fining is ironic  since nearly half of all users say they woul stop using search engines if they thought engines were not being clear about how they presente pai results   commenting mr macklin sai sponsore results must be clearly marke an though they might help with some queries user testing showe that people nee to be able to spot the ifference '"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#remove numbers \n",
    "data['text1'][0] = ''.join([i for i in data['text1'][0] if not i.isdigit()])\n",
    "data['text1'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fa1b9d9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SaLmA\\AppData\\Local\\Temp/ipykernel_11964/4096739572.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['text2'][0] = ''.join([i for i in data['text1'][0] if not i.isdigit()])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'savvy searchers fail to spot as internet search engine users are an o mix of naive an sophisticate  suggests a report into search habits   the report by the us pew research center reveals that   of searchers usually fin what they were looking for when using a search engine  it also shows that few can spot the ifference between pai for results an organic ones  the report reveals that   of net users say they regularly use google  ask jeeves  msn an yahoo when online   almost   of those questione sai they woul trust search engines much less  if they knew information about who pai for results was being hien  accoring to figures gathere by the pew researchers the average users spens about  minutes per month carrying out  separate searches an looks at   webpages for each hunt  a significant chunk of net users     carry out a search at least weekly an   of those aske only look every few weeks  for   of those questione  the information they are looking for is critical to what they are oing an is information they simply have to fin   search engine users also ten to be very loyal an once they have foun a site they feel they can trust ten to stick with it  accoring to pew research   of searchers use just a single search engine    use two or three an a small number     consult more than three sites  tony macklin  spokesman for ask jeeves  sai the results reflecte its own research which showe that people use ifferent search engines because the way the sites gather information means they can provie ifferent results for the same query  espite this liking for search sites half of those questione sai they coul get the same information via other routes  a small number     sai they wouln t really miss search engines if they i not exist  the remaining   sai they coul not live without search sites  more than two thirs of those questione     sai they thought that the results they were presente with were a fair an unbiase selection of the information on a topic that can be foun on the net  alongsie the growing sophistication of net users is a lack of awareness about pai for results that many search engines provie alongsie lists of websites foun by inexing the web  of those aske    were unaware that someone has pai for some of the results they see when they carry out a search  only   of all searchers say they can tell which results are pai for an which are not  sai the pew report   this fining is ironic  since nearly half of all users say they woul stop using search engines if they thought engines were not being clear about how they presente pai results   commenting mr macklin sai sponsore results must be clearly marke an though they might help with some queries user testing showe that people nee to be able to spot the ifference '"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['text2'][0] = ''.join([i for i in data['text1'][0] if not i.isdigit()])\n",
    "data['text2'][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ec55b2ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'savvy searchers fail spot internet search engine users mix naive sophisticate suggests report search habits report us pew research center reveals searchers usually fin looking using search engine also shows spot ifference pai results organic ones report reveals net users say regularly use google ask jeeves msn yahoo online almost questione sai woul trust search engines much less knew information pai results hien accoring figures gathere pew researchers average users spens minutes per month carrying separate searches looks webpages hunt significant chunk net users carry search least weekly aske look every weeks questione information looking critical oing information simply fin search engine users also ten loyal foun site feel trust ten stick accoring pew research searchers use single search engine use two three small number consult three sites tony macklin spokesman ask jeeves sai results reflecte research showe people use ifferent search engines way sites gather information means provie ifferent results query espite liking search sites half questione sai coul get information via routes small number sai wouln really miss search engines exist remaining sai coul live without search sites two thirs questione sai thought results presente fair unbiase selection information topic foun net alongsie growing sophistication net users lack awareness pai results many search engines provie alongsie lists websites foun inexing web aske unaware someone pai results see carry search searchers say tell results pai sai pew report fining ironic since nearly half users say woul stop using search engines thought engines clear presente pai results commenting mr macklin sai sponsore results must clearly marke though might help queries user testing showe people nee able spot ifference'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#removing stopwords of text1 column\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stop_words.add('subject')\n",
    "stop_words.add('http')\n",
    "def remove_stopwords(text1):              \n",
    "    return \" \".join([word for word in str(text1).split() if word not in stop_words])\n",
    "data['text1'] = data['text1'].apply(lambda x: remove_stopwords(x))\n",
    "data['text1'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "55072811",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'savvy searchers fail spot internet search engine users mix naive sophisticate suggests report search habits report us pew research center reveals searchers usually fin looking using search engine also shows spot ifference pai results organic ones report reveals net users say regularly use google ask jeeves msn yahoo online almost questione sai woul trust search engines much less knew information pai results hien accoring figures gathere pew researchers average users spens minutes per month carrying separate searches looks webpages hunt significant chunk net users carry search least weekly aske look every weeks questione information looking critical oing information simply fin search engine users also ten loyal foun site feel trust ten stick accoring pew research searchers use single search engine use two three small number consult three sites tony macklin spokesman ask jeeves sai results reflecte research showe people use ifferent search engines way sites gather information means provie ifferent results query espite liking search sites half questione sai coul get information via routes small number sai wouln really miss search engines exist remaining sai coul live without search sites two thirs questione sai thought results presente fair unbiase selection information topic foun net alongsie growing sophistication net users lack awareness pai results many search engines provie alongsie lists websites foun inexing web aske unaware someone pai results see carry search searchers say tell results pai sai pew report fining ironic since nearly half users say woul stop using search engines thought engines clear presente pai results commenting mr macklin sai sponsore results must clearly marke though might help queries user testing showe people nee able spot ifference'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#removing stopwords of text2 column\n",
    "def remove_stopwords(text2):              \n",
    "    return \" \".join([word for word in str(text2).split() if word not in stop_words])\n",
    "data['text2'] = data['text2'].apply(lambda x: remove_stopwords(x))\n",
    "data['text2'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1863d222",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'savvi searcher fail spot internet search engin user mix naiv sophist suggest report search habit report us pew research center reveal searcher usual fin look use search engin also show spot iffer pai result organ one report reveal net user say regularli use googl ask jeev msn yahoo onlin almost question sai woul trust search engin much less knew inform pai result hien accor figur gather pew research averag user spen minut per month carri separ search look webpag hunt signific chunk net user carri search least weekli ask look everi week question inform look critic o inform simpli fin search engin user also ten loyal foun site feel trust ten stick accor pew research searcher use singl search engin use two three small number consult three site toni macklin spokesman ask jeev sai result reflect research show peopl use iffer search engin way site gather inform mean provi iffer result queri espit like search site half question sai coul get inform via rout small number sai wouln realli miss search engin exist remain sai coul live without search site two thir question sai thought result present fair unbias select inform topic foun net alongsi grow sophist net user lack awar pai result mani search engin provi alongsi list websit foun inex web ask unawar someon pai result see carri search searcher say tell result pai sai pew report fine iron sinc nearli half user say woul stop use search engin thought engin clear present pai result comment mr macklin sai sponsor result must clearli mark though might help queri user test show peopl nee abl spot iffer'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#stemming\n",
    "from nltk.stem import PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "def stem_words(text1):\n",
    "    return \" \".join([stemmer.stem(word) for word in text1.split()])\n",
    "data[\"text1\"] = data[\"text1\"].apply(lambda x: stem_words(x))\n",
    "data[\"text1\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "adcf978d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'savvi searcher fail spot internet search engin user mix naiv sophist suggest report search habit report us pew research center reveal searcher usual fin look use search engin also show spot iffer pai result organ one report reveal net user say regularli use googl ask jeev msn yahoo onlin almost question sai woul trust search engin much less knew inform pai result hien accor figur gather pew research averag user spen minut per month carri separ search look webpag hunt signific chunk net user carri search least weekli ask look everi week question inform look critic o inform simpli fin search engin user also ten loyal foun site feel trust ten stick accor pew research searcher use singl search engin use two three small number consult three site toni macklin spokesman ask jeev sai result reflect research show peopl use iffer search engin way site gather inform mean provi iffer result queri espit like search site half question sai coul get inform via rout small number sai wouln realli miss search engin exist remain sai coul live without search site two thir question sai thought result present fair unbias select inform topic foun net alongsi grow sophist net user lack awar pai result mani search engin provi alongsi list websit foun inex web ask unawar someon pai result see carri search searcher say tell result pai sai pew report fine iron sinc nearli half user say woul stop use search engin thought engin clear present pai result comment mr macklin sai sponsor result must clearli mark though might help queri user test show peopl nee abl spot iffer'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def stem_words(text2):\n",
    "    return \" \".join([stemmer.stem(word) for word in text2.split()])\n",
    "data[\"text2\"] = data[\"text2\"].apply(lambda x: stem_words(x))\n",
    "data[\"text2\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "17429851",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'savvi searcher fail spot internet search engin user mix naiv sophist suggest report search habit report u pew research center reveal searcher usual fin look use search engin also show spot iffer pai result organ one report reveal net user say regularli use googl ask jeev msn yahoo onlin almost question sai woul trust search engin much le knew inform pai result hien accor figur gather pew research averag user spen minut per month carri separ search look webpag hunt signific chunk net user carri search least weekli ask look everi week question inform look critic o inform simpli fin search engin user also ten loyal foun site feel trust ten stick accor pew research searcher use singl search engin use two three small number consult three site toni macklin spokesman ask jeev sai result reflect research show peopl use iffer search engin way site gather inform mean provi iffer result queri espit like search site half question sai coul get inform via rout small number sai wouln realli miss search engin exist remain sai coul live without search site two thir question sai thought result present fair unbias select inform topic foun net alongsi grow sophist net user lack awar pai result mani search engin provi alongsi list websit foun inex web ask unawar someon pai result see carri search searcher say tell result pai sai pew report fine iron sinc nearli half user say woul stop use search engin thought engin clear present pai result comment mr macklin sai sponsor result must clearli mark though might help queri user test show peopl nee abl spot iffer'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lemmatization\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "def lemmatize_words(text1):\n",
    "    return \" \".join([lemmatizer.lemmatize(word) for word in text1.split()])\n",
    "data[\"text1\"] = data[\"text1\"].apply(lambda text1: lemmatize_words(text1))\n",
    "data[\"text1\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b22dbb20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'savvi searcher fail spot internet search engin user mix naiv sophist suggest report search habit report u pew research center reveal searcher usual fin look use search engin also show spot iffer pai result organ one report reveal net user say regularli use googl ask jeev msn yahoo onlin almost question sai woul trust search engin much le knew inform pai result hien accor figur gather pew research averag user spen minut per month carri separ search look webpag hunt signific chunk net user carri search least weekli ask look everi week question inform look critic o inform simpli fin search engin user also ten loyal foun site feel trust ten stick accor pew research searcher use singl search engin use two three small number consult three site toni macklin spokesman ask jeev sai result reflect research show peopl use iffer search engin way site gather inform mean provi iffer result queri espit like search site half question sai coul get inform via rout small number sai wouln realli miss search engin exist remain sai coul live without search site two thir question sai thought result present fair unbias select inform topic foun net alongsi grow sophist net user lack awar pai result mani search engin provi alongsi list websit foun inex web ask unawar someon pai result see carri search searcher say tell result pai sai pew report fine iron sinc nearli half user say woul stop use search engin thought engin clear present pai result comment mr macklin sai sponsor result must clearli mark though might help queri user test show peopl nee abl spot iffer'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "def lemmatize_words(text2):\n",
    "    return \" \".join([lemmatizer.lemmatize(word) for word in text2.split()])\n",
    "data[\"text2\"] = data[\"text2\"].apply(lambda text2: lemmatize_words(text2))\n",
    "data[\"text2\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "478496d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'savvi searcher fail spot internet search engin user mix naiv sophist suggest report search habit report u pew research center reveal searcher usual fin look use search engin also show spot iffer pai result organ one report reveal net user say regularli use googl ask jeev msn yahoo onlin almost question sai woul trust search engin much le knew inform pai result hien accor figur gather pew research averag user spen minut per month carri separ search look webpag hunt signific chunk net user carri search least weekli ask look everi week question inform look critic o inform simpli fin search engin user also ten loyal foun site feel trust ten stick accor pew research searcher use singl search engin use two three small number consult three site toni macklin spokesman ask jeev sai result reflect research show peopl use iffer search engin way site gather inform mean provi iffer result queri espit like search site half question sai coul get inform via rout small number sai wouln realli miss search engin exist remain sai coul live without search site two thir question sai thought result present fair unbias select inform topic foun net alongsi grow sophist net user lack awar pai result mani search engin provi alongsi list websit foun inex web ask unawar someon pai result see carri search searcher say tell result pai sai pew report fine iron sinc nearli half user say woul stop use search engin thought engin clear present pai result comment mr macklin sai sponsor result must clearli mark though might help queri user test show peopl nee abl spot iffer'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#remove extra spacing \n",
    "data['text1'][0].strip()\n",
    "data['text1'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1c7b63a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'savvi searcher fail spot internet search engin user mix naiv sophist suggest report search habit report u pew research center reveal searcher usual fin look use search engin also show spot iffer pai result organ one report reveal net user say regularli use googl ask jeev msn yahoo onlin almost question sai woul trust search engin much le knew inform pai result hien accor figur gather pew research averag user spen minut per month carri separ search look webpag hunt signific chunk net user carri search least weekli ask look everi week question inform look critic o inform simpli fin search engin user also ten loyal foun site feel trust ten stick accor pew research searcher use singl search engin use two three small number consult three site toni macklin spokesman ask jeev sai result reflect research show peopl use iffer search engin way site gather inform mean provi iffer result queri espit like search site half question sai coul get inform via rout small number sai wouln realli miss search engin exist remain sai coul live without search site two thir question sai thought result present fair unbias select inform topic foun net alongsi grow sophist net user lack awar pai result mani search engin provi alongsi list websit foun inex web ask unawar someon pai result see carri search searcher say tell result pai sai pew report fine iron sinc nearli half user say woul stop use search engin thought engin clear present pai result comment mr macklin sai sponsor result must clearli mark though might help queri user test show peopl nee abl spot iffer'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['text2'][0].strip()\n",
    "data['text2'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce7bc94",
   "metadata": {},
   "source": [
    "# sentence similarity algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2a391f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_sent=data.loc[data['Unique_ID']==748 , 'text1'].iloc[0] #reference sentence .. for extracting similar sentences\n",
    "#randomly selected row to be the source sentence for finding 5 similarities with the help of jensem library\n",
    "#iloc[0] because it is the first col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f5c34980",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'kilroy name elect seat target ex chat show host robert kilroy silk contest erbyshir seat erewash next gener elect labour elizabeth blackman seat 1997 6 932 major say fight recor har work constitu mp mr kilroy silk announc plan ay launch new parti verita latin truth east milan mep quit uk inepen parti want new group chang face uk polit choic elect constitu quash specul woul stan efenc secretari geoff hoon ashfiel nottinghamshir ukip 31 vote erewash last june european elect mr kilroy silk among caniat region 1997 erewash ha hel torus sinc 1970 m blackman sai prou govern achiev area eclin give view mr kilroy silk point thursay tol lonon news confer verita woul avoi ol parti lie spin sai countri stolen u mass immigr promis firm fair polici immigr verita say hope contest seat forthcom gener elect plan announc etail polici crime tax pension health efenc next week ukip leaer roger knapman say gla see back mr kilroy silk labour campaign spokesman fraser kemp sai verita join alreay crow fiel right british polit mr kilroy silk join new ventur one ukip two lonon assembl member amien hockney verita eputi leaer ukip chairman petrina holsworth sai group paroy parti men left mr kilroy silk quit ukip last week month tension vie unsuccess leaership parti sai asham member ukip whose leaership ha gone awol great opportun offer thir place last june european elect ukip leaer roger knapman sai gla see back mr kilroy silk remark abil influenc peopl sali european elect becam clear interest robert kilroy silk parti uk inepen parti nice know gooby sai ukip offici also argu mr kilroy silk straightforwar attack parti want lea'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref_sent #this is the ref_sent for which we will find 5 similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5c0a5b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_sent_vec=nlp(ref_sent) #vectorize tokens using nlp .. ref_sent is a parameter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "81c0275c",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_docs=[nlp(row) for row in data['text1']] #this is my text saved on all_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0700e6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#forloop to extract similar sentences to the ref_sent\n",
    "#create 2 empty lists because for every similar sent, we need to calculate similarity score+know doc_id \n",
    "sims=[]\n",
    "doc_id=[] \n",
    "for i in range (len(all_docs)):\n",
    "    sim=all_docs[i].similarity(ref_sent_vec) #similarity is given in genism lib\n",
    "    sims.append(sim) #similar sent saved here\n",
    "    doc_id.append(i)\n",
    "    sims_docs=pd.DataFrame(list(zip(doc_id,sims)) , columns=['doc_id','sims']) #dataframe have 2 cols doc_id&sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "000af3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to sort similarities\n",
    "sims_docs_sorted=sims_docs.sort_values(by= 'sims',ascending=False) #it is descending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c8c0aa50",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_5_sim_docs = data.iloc[sims_docs_sorted['doc_id'][1:6]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ffe9bb6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['kilroy name elect seat target ex chat show host robert kilroy silk contest erbyshir seat erewash next gener elect labour elizabeth blackman seat 1997 6 932 major say fight recor har work constitu mp mr kilroy silk announc plan ay launch new parti verita latin truth east milan mep quit uk inepen parti want new group chang face uk polit choic elect constitu quash specul woul stan efenc secretari geoff hoon ashfiel nottinghamshir ukip 31 vote erewash last june european elect mr kilroy silk among caniat region 1997 erewash ha hel torus sinc 1970 m blackman sai prou govern achiev area eclin give view mr kilroy silk point thursay tol lonon news confer verita woul avoi ol parti lie spin sai countri stolen u mass immigr promis firm fair polici immigr verita say hope contest seat forthcom gener elect plan announc etail polici crime tax pension health efenc next week ukip leaer roger knapman say gla see back mr kilroy silk labour campaign spokesman fraser kemp sai verita join alreay crow fiel right british polit mr kilroy silk join new ventur one ukip two lonon assembl member amien hockney verita eputi leaer ukip chairman petrina holsworth sai group paroy parti men left mr kilroy silk quit ukip last week month tension vie unsuccess leaership parti sai asham member ukip whose leaership ha gone awol great opportun offer thir place last june european elect ukip leaer roger knapman sai gla see back mr kilroy silk remark abil influenc peopl sali european elect becam clear interest robert kilroy silk parti uk inepen parti nice know gooby sai ukip offici also argu mr kilroy silk straightforwar attack parti want lea']\n"
     ]
    }
   ],
   "source": [
    "print(data[data['Unique_ID']==748]['text1'].values)#print top similarities and scores according to ref sent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3b281a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_sim_scores=pd.concat([top_5_sim_docs,sims_docs_sorted['sims'][1:6]],axis=1)\n",
    "#to get create data frame for top docs & sorted sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0befba40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top 5 similar sentences are:kilroy name elect seat target ex chat show host robert kilroy silk contest erbyshir seat erewash next gener elect labour elizabeth blackman seat 1997 6 932 major say fight recor har work constitu mp mr kilroy silk announc plan ay launch new parti verita latin truth east milan mep quit uk inepen parti want new group chang face uk polit choic elect constitu quash specul woul stan efenc secretari geoff hoon ashfiel nottinghamshir ukip 31 vote erewash last june european elect mr kilroy silk among caniat region 1997 erewash ha hel torus sinc 1970 m blackman sai prou govern achiev area eclin give view mr kilroy silk point thursay tol lonon news confer verita woul avoi ol parti lie spin sai countri stolen u mass immigr promis firm fair polici immigr verita say hope contest seat forthcom gener elect plan announc etail polici crime tax pension health efenc next week ukip leaer roger knapman say gla see back mr kilroy silk labour campaign spokesman fraser kemp sai verita join alreay crow fiel right british polit mr kilroy silk join new ventur one ukip two lonon assembl member amien hockney verita eputi leaer ukip chairman petrina holsworth sai group paroy parti men left mr kilroy silk quit ukip last week month tension vie unsuccess leaership parti sai asham member ukip whose leaership ha gone awol great opportun offer thir place last june european elect ukip leaer roger knapman sai gla see back mr kilroy silk remark abil influenc peopl sali european elect becam clear interest robert kilroy silk parti uk inepen parti nice know gooby sai ukip offici also argu mr kilroy silk straightforwar attack parti want lea\n",
      " with a similarity score of 1.00\n",
      "\n",
      "The top 5 similar sentences are:kilroy silk quit shame ukip ex chat show host robert kilroy silk quit uk inepen parti accus betray support mep sai asham join parti label joke plan stan next gener elect refus confirm set new polit parti call verita latin truth ukip leaer roger knapman sai woul break open champagn a nice know gooby howev say ex chat show host ha quit use initi remark abil influenc peopl sali european elect becam clear interest robert kilroy silk parti uk inepen parti nice know gooby mr knapman tol bbc raio 4 toay programm mr knapman reject iea mr kilroy silk pose threat ukip queri ha fail confirm rumour start new polit parti mr kilroy silk explain reason east milan constitu meet hinckley leicestershir ecis came ukip offici began process coul trigger mr kilroy silk expuls mark en membership ukip nine month began floo public help ukip thir place last june european elect becam omin rancour trie take parti leaership mr kilroy silk accus fellow ukip mep content grow fat sit backsi brussel tol bbc news 24 trie chang parti nagg way summer thing get move thought crimin o betray mr kilroy silk also tol sky news mass support form new parti someth yet confirm happen ukip 12 seat 16 1 vote european elect back call uk leav european union speech mr kilroy silk say result offer ukip amaz opportun parti leaership ha one noth gone awol polici energi vision spokespeopl sai parti go nowher embarrass alli europ asham member parti sai mr kilroy silk sai convict britain right govern ha chang woul continu campaign outsi ukip contest gener elect east milan constitu report new parti plan prompt formal complaint ukip isciplinari committe bring parti isreput thursay parti challeng mr kilroy silk stan mep voter get genuin ukip caniat\n",
      " with a similarity score of 0.98\n",
      "\n",
      "The top 5 similar sentences are:kilroy silk quit shame ukip ex chat show host robert kilroy silk quit uk inepen parti accus betray support mep sai asham join parti label joke plan stan next gener elect refus confirm set new polit parti call verita latin truth ukip leaer roger knapman sai woul break open champagn a nice know gooby howev say ex chat show host ha quit use initi remark abil influenc peopl sali european elect becam clear interest robert kilroy silk parti uk inepen parti nice know gooby mr knapman tol bbc raio 4 toay programm mr knapman reject iea mr kilroy silk pose threat ukip queri ha fail confirm rumour start new polit parti mr kilroy silk explain reason east milan constitu meet hinckley leicestershir ecis came ukip offici began process coul trigger mr kilroy silk expuls mark en membership ukip nine month began floo public help ukip thir place last june european elect becam omin rancour trie take parti leaership mr kilroy silk accus fellow ukip mep content grow fat sit backsi brussel tol bbc news 24 trie chang parti nagg way summer thing get move thought crimin o betray mr kilroy silk also tol sky news mass support form new parti someth yet confirm happen ukip 12 seat 16 1 vote european elect back call uk leav european union speech mr kilroy silk say result offer ukip amaz opportun parti leaership ha one noth gone awol polici energi vision spokespeopl sai parti go nowher embarrass alli europ asham member parti sai mr kilroy silk sai convict britain right govern ha chang woul continu campaign outsi ukip contest gener elect east milan constitu report new parti plan prompt formal complaint ukip isciplinari committe bring parti isreput thursay parti challeng mr kilroy silk stan mep voter get genuin ukip caniat\n",
      " with a similarity score of 0.98\n",
      "\n",
      "The top 5 similar sentences are:kilroy launch verita parti ex bbc chat show host east milan mep robert kilroy silk sai want chang face british polit launch new parti mr kilroy silk recent quit uk inepen parti sai countri stolen u mass immigr tol lonon news confer verita latin truth woul avoi ol parti lie spin ukip leaer roger knapman say gla see back mr kilroy silk mr kilroy silk promis firm fair polici immigr sai hope contest seat forthcom gener elect sai verita woul also announc etail polici crime tax pension health efenc next week announc parti woul hole leaership elect thursay ue announc constitu run next gener elect come ami specul sight set efenc secretari geoff hoon ashfiel seat join new ventur one ukip two lonon assembl member amien hockney verita eputi leaer ukip chairman petrina holsworth sai group paroy parti men left mr kilroy silk announc ecis quit ukip public meet hinckley leicestershir last week came month tension vie unsuccess leaership parti sai asham member ukip whose leaership ha gone awol great opportun offer thir place last june european elect ukip turn back british peopl shall sai stane next gener elect shall lea vigor campaign caus believ unlik ol parti shall honest open straight mr hockney also left ukip say mr kilroy silk woul eliv better leaer euroscept parti spokesman ukip call mr hockney quit lonon assembl parti assert mr hockney moral oblig legal one stan leaer roger knapman sai gla see back mr kilroy silk remark abil influenc peopl sali european elect becam clear interest robert kilroy silk parti uk inepen parti nice know gooby sai ukip offici also argu mr kilroy silk straightforwar attack parti want lea europhil pray main euroscept parti ukip shoul tri resolv iffer kilroy show unit front give uk public seriou polit voic europ multipl parti view point split vote thank gooness kilroy silk gone ukip least chanc elect sa see caus britain regain proper relationship europ amag split within ukip robert kilroy silk coul lot offer instea split parti amag caus uner present elector system peopl must work togeth small parti hope represent last summer ukip achiev major avanc partli partli ue kilroy silk great shame issip fight ukip wie platform polici withraw eu kilroy silk conveni ignor comment surroun launch parti neither english emocrat new parti interest let join take leaership speak volum verita begin en kilroy silk believ truth emocraci two assembl member shoul resign forc elect stan platform rather backoor approach polit elect one parti efect anoth ukip goo enough lea goo enough follow interest parti committ plain speak shoul latin name everi opinion poll point overwhelm anti europ feel countri kilroy silk coul verg someth huge broaen appeal beyon one issu extrem abl commun year polit experi want qualiti school top hospit clean effici public transport punish fit crime limit asylum purg bureaucraci le tax nee courag honesti two qualiti sali lack politician kilroy silk may qualiti recruit right colleagu robert time may come well cannot get enough limelight orinari mp go start parti flash real polici let hope start ukip kilroy silk slip obscur verita name oom perhap wrong sure moern schoolchilren unerstan sinc still learn latin classroom whole essenc rk repres eurosceptic explain twee label verita symbolis\n",
      " with a similarity score of 0.98\n",
      "\n",
      "The top 5 similar sentences are:kilroy launch verita parti ex bbc chat show host east milan mep robert kilroy silk sai want chang face british polit launch new parti mr kilroy silk recent quit uk inepen parti sai countri stolen u mass immigr tol lonon news confer verita latin truth woul avoi ol parti lie spin ukip leaer roger knapman say gla see back mr kilroy silk mr kilroy silk promis firm fair polici immigr sai hope contest seat forthcom gener elect sai verita woul also announc etail polici crime tax pension health efenc next week announc parti woul hole leaership elect thursay ue announc constitu run next gener elect come ami specul sight set efenc secretari geoff hoon ashfiel seat join new ventur one ukip two lonon assembl member amien hockney verita eputi leaer ukip chairman petrina holsworth sai group paroy parti men left mr kilroy silk announc ecis quit ukip public meet hinckley leicestershir last week came month tension vie unsuccess leaership parti sai asham member ukip whose leaership ha gone awol great opportun offer thir place last june european elect ukip turn back british peopl shall sai stane next gener elect shall lea vigor campaign caus believ unlik ol parti shall honest open straight mr hockney also left ukip say mr kilroy silk woul eliv better leaer euroscept parti spokesman ukip call mr hockney quit lonon assembl parti assert mr hockney moral oblig legal one stan leaer roger knapman sai gla see back mr kilroy silk remark abil influenc peopl sali european elect becam clear interest robert kilroy silk parti uk inepen parti nice know gooby sai ukip offici also argu mr kilroy silk straightforwar attack parti want lea europhil pray main euroscept parti ukip shoul tri resolv iffer kilroy show unit front give uk public seriou polit voic europ multipl parti view point split vote thank gooness kilroy silk gone ukip least chanc elect sa see caus britain regain proper relationship europ amag split within ukip robert kilroy silk coul lot offer instea split parti amag caus uner present elector system peopl must work togeth small parti hope represent last summer ukip achiev major avanc partli partli ue kilroy silk great shame issip fight ukip wie platform polici withraw eu kilroy silk conveni ignor comment surroun launch parti neither english emocrat new parti interest let join take leaership speak volum verita begin en kilroy silk believ truth emocraci two assembl member shoul resign forc elect stan platform rather backoor approach polit elect one parti efect anoth ukip goo enough lea goo enough follow interest parti committ plain speak shoul latin name everi opinion poll point overwhelm anti europ feel countri kilroy silk coul verg someth huge broaen appeal beyon one issu extrem abl commun year polit experi want qualiti school top hospit clean effici public transport punish fit crime limit asylum purg bureaucraci le tax nee courag honesti two qualiti sali lack politician kilroy silk may qualiti recruit right colleagu robert time may come well cannot get enough limelight orinari mp go start parti flash real polici let hope start ukip kilroy silk slip obscur verita name oom perhap wrong sure moern schoolchilren unerstan sinc still learn latin classroom whole essenc rk repres eurosceptic explain twee label verita symbolis\n",
      " with a similarity score of 0.98\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for(text1,sim) in zip (top_sim_scores['text1'],top_sim_scores['sims']):\n",
    "    print(\"The top 5 similar sentences are:{}\\n with a similarity score of {:.2f}\\n\".format(text1,sim))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
